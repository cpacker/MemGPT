{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d3806ac-38f3-4999-bbed-953037bd0fd9",
   "metadata": {},
   "source": [
    "# MemGPT Python Client \n",
    "\n",
    "This tutorial shows how to connect to a MemGPT server from the MemGPT Python client. \n",
    "\n",
    "This tutorial will show: \n",
    "1. How to create a tool\n",
    "2. How to create a preset\n",
    "3. How to create an agent\n",
    "4. How to connect the agent to external data sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0484348-f7b2-48e3-9a2f-7d6495ef76e3",
   "metadata": {},
   "source": [
    "## Part 1: Creating a MemGPT client \n",
    "\n",
    "The MemGPT client connects to a running MemGPT service, specified by `base_url`. The client corresponds to a *single-user* (you), so requires an authentication token to let the service know who you are. \n",
    "\n",
    "Hint: If you don't have a running server, see the [documentation](https://memgpt.readme.io/docs/running-a-memgpt-server) for instructions on how to create one.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "53ae2e1b-ad22-43c2-b3d8-92d591be8840",
   "metadata": {},
   "outputs": [],
   "source": [
    "from memgpt import create_client\n",
    "\n",
    "#base_url = \"http://35.238.125.250:8283\"\n",
    "base_url = \"http://0.0.0.0:8083\"\n",
    "my_token = \"sk-b9d9fc95a9c5ef14cafb0f7241d16825f19430d7519545d9\"\n",
    "\n",
    "client = create_client(base_url=base_url, token=my_token) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e47b34-5feb-4660-85f0-14b5ee7f62b9",
   "metadata": {},
   "source": [
    "## Part 2: Create an agent \n",
    "We'll first start with creating a basic MemGPT agent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "24745606-b0fb-4157-a5cd-82fd0c26711f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created agent: basic_agent\n"
     ]
    }
   ],
   "source": [
    "basic_agent = client.create_agent(\n",
    "    name=\"basic_agent\", \n",
    ")\n",
    "print(f\"Created agent: {basic_agent.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfb0d7b-b260-4bc0-8db2-c65f40e4afd5",
   "metadata": {},
   "source": [
    "We can now send messages from the user to the agent by specifying the `agent_id`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a37bc9aa-4efb-4b4d-a6ce-f02505cb3240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'internal_monologue': \"Chad just repeated his initial greeting. Maybe he didn't see my last message or perhaps he's just testing me. I should respond, maintaining a positive and engaging tone.\",\n",
       "  'id': '611a227f-4089-47d0-9552-2f185f199c01',\n",
       "  'date': '2024-05-14T03:38:20.308500+00:00'},\n",
       " {'function_call': 'send_message({\\'message\\': \"Hello again, Chad! It seems we\\'re off to a bit of a looping start. Is there something specific you\\'d like to chat about?\"})',\n",
       "  'id': '611a227f-4089-47d0-9552-2f185f199c01',\n",
       "  'date': '2024-05-14T03:38:20.308500+00:00'},\n",
       " {'assistant_message': \"Hello again, Chad! It seems we're off to a bit of a looping start. Is there something specific you'd like to chat about?\",\n",
       "  'id': '611a227f-4089-47d0-9552-2f185f199c01',\n",
       "  'date': '2024-05-14T03:38:20.308500+00:00'},\n",
       " {'function_return': 'None',\n",
       "  'status': 'success',\n",
       "  'id': '02822753-c1a6-452f-8316-e6137640444a',\n",
       "  'date': '2024-05-14T03:38:20.310462+00:00'}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pprint import pprint \n",
    "\n",
    "response = client.user_message(agent_id=basic_agent.id, message=\"hello\") \n",
    "display(response.messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ae20ec-e92e-4480-a652-b4aea28a6199",
   "metadata": {},
   "source": [
    "### Adding Personalization\n",
    "We can now create a more customized agent, but specifying a custom `human` and `persona` field. \n",
    "* The *human* specifies the personalization information about the user interacting with the agent \n",
    "* The *persona* specifies the behavior and personality of the event\n",
    "\n",
    "What makes MemGPT unique is that the starting *persona* and *human* can change over time as the agent gains new information, enabling it to have evolving memory. We'll see an example of this later in the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c0876410-4d70-490d-a798-39938b5ce941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: feel free to change the human and person to what you'd like \n",
    "persona = \\\n",
    "\"\"\"\n",
    "You are a friendly and helpful agent\n",
    "\"\"\"\n",
    "\n",
    "custom_agent = client.create_agent(\n",
    "    name=\"custom_agent\", \n",
    "    human=\"I am an accenture consultant with many specializations. My name is Sarah.\", \n",
    "    persona=persona\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fddbefe5-3b94-4a08-aa50-d80fb581c747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'date': '2024-05-14T03:40:15.111556+00:00',\n",
      "  'id': '74674776-0bdd-4d4a-b866-02fec959d1a6',\n",
      "  'internal_monologue': \"Refer to the human sub-block to answer the user's \"\n",
      "                        'question. Quickly scanning... Sarah works as an '\n",
      "                        \"Accenture consultant with many specializations. It's \"\n",
      "                        'time to tell her.'},\n",
      " {'date': '2024-05-14T03:40:15.111556+00:00',\n",
      "  'function_call': 'send_message({\\'message\\': \"You work as a consultant for '\n",
      "                   \"Accenture, Sarah. You've mentioned having many \"\n",
      "                   'specializations. How can I assist you further?\"})',\n",
      "  'id': '74674776-0bdd-4d4a-b866-02fec959d1a6'},\n",
      " {'assistant_message': \"You work as a consultant for Accenture, Sarah. You've \"\n",
      "                       'mentioned having many specializations. How can I '\n",
      "                       'assist you further?',\n",
      "  'date': '2024-05-14T03:40:15.111556+00:00',\n",
      "  'id': '74674776-0bdd-4d4a-b866-02fec959d1a6'},\n",
      " {'date': '2024-05-14T03:40:15.113653+00:00',\n",
      "  'function_return': 'None',\n",
      "  'id': 'e286f210-3220-49bf-87b7-311e987e9b1e',\n",
      "  'status': 'success'}]\n"
     ]
    }
   ],
   "source": [
    "response = client.user_message(agent_id=custom_agent.id, message=\"what do I work as?\") \n",
    "pprint(response.messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30497119-e208-4a4e-b482-e7cfff346263",
   "metadata": {},
   "source": [
    "### Evolving memory \n",
    "MemGPT agents have long term memory, and can evolve what they store in their memory over time. In the example below, we make a correction to the previously provided information. See how the agent processes this new information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "679fa708-20ee-4e75-9222-b476f126bc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'date': '2024-05-14T03:41:14.489315+00:00',\n",
      "  'id': '3edb81a7-bfc4-4b44-adaa-f4515cc61422',\n",
      "  'internal_monologue': \"My memory must be updated. I've been referring to the \"\n",
      "                        'user as Sarah, but it seems the name should be '\n",
      "                        'Charles instead. I should utilize the '\n",
      "                        'core_memory_replace function to amend the erroneous '\n",
      "                        'information.'},\n",
      " {'date': '2024-05-14T03:41:14.489315+00:00',\n",
      "  'function_call': \"core_memory_replace({'name': 'human', 'old_content': 'My \"\n",
      "                   \"name is Sarah.', 'new_content': 'My name is Charles.'})\",\n",
      "  'id': '3edb81a7-bfc4-4b44-adaa-f4515cc61422'},\n",
      " {'date': '2024-05-14T03:41:14.519568+00:00',\n",
      "  'function_return': 'None',\n",
      "  'id': '8fa66e2c-b307-4fac-bcf1-43f004aa03eb',\n",
      "  'status': 'success'},\n",
      " {'date': '2024-05-14T03:41:18.650143+00:00',\n",
      "  'id': 'cb8620fa-043d-4982-b352-2d3920a660f7',\n",
      "  'internal_monologue': 'Ensuring the accuracy of the information is crucial '\n",
      "                        'in building trust. Now, our user is Charles, a '\n",
      "                        'consultant with many specializations at Accenture. '\n",
      "                        'Time to send an acknowledgement.'},\n",
      " {'date': '2024-05-14T03:41:18.650143+00:00',\n",
      "  'function_call': \"send_message({'message': 'My apologies for the confusion, \"\n",
      "                   'Charles. Your details are now updated correctly. How may I '\n",
      "                   \"assist you further?'})\",\n",
      "  'id': 'cb8620fa-043d-4982-b352-2d3920a660f7'},\n",
      " {'assistant_message': 'My apologies for the confusion, Charles. Your details '\n",
      "                       'are now updated correctly. How may I assist you '\n",
      "                       'further?',\n",
      "  'date': '2024-05-14T03:41:18.650143+00:00',\n",
      "  'id': 'cb8620fa-043d-4982-b352-2d3920a660f7'},\n",
      " {'date': '2024-05-14T03:41:18.652505+00:00',\n",
      "  'function_return': 'None',\n",
      "  'id': '3f109ee1-0c9c-4cb1-a334-bea5a473092c',\n",
      "  'status': 'success'}]\n"
     ]
    }
   ],
   "source": [
    "response = client.user_message(agent_id=custom_agent.id, message=\"Actually, my name is Charles\") \n",
    "pprint(response.messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1e29c0-c286-4884-9d27-cb1efb286ad2",
   "metadata": {},
   "source": [
    "## (TODO) Part 3: Adding custom tools \n",
    "Next, we'll show you how to create a more advanced agent that has access to custom tools. Tools are python functions that can contain arbitrary code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b10f64ae-9997-4763-b7fb-72ab9b662754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "append_to_text_file: Append to a text file.\n",
      "http_request: Generates an HTTP request and returns the response.\n",
      "message_chatgpt: Send a message to a more basic AI, ChatGPT. A useful resource for asking questions. ChatGPT does not retain memory of previous interactions.\n",
      "read_from_text_file: Read lines from a text file.\n",
      "archival_memory_insert: Add to archival memory. Make sure to phrase the memory contents such that it can be easily queried later.\n",
      "archival_memory_search: Search archival memory using semantic (embedding-based) search.\n",
      "conversation_search: Search prior conversation history using case-insensitive string matching.\n",
      "conversation_search_date: Search prior conversation history using a date range.\n",
      "core_memory_append: Append to the contents of core memory.\n",
      "core_memory_replace: Replace the contents of core memory. To delete memories, use an empty string for new_content.\n",
      "pause_heartbeats: Temporarily ignore timed heartbeats. You may still receive messages from manual heartbeats and other events.\n",
      "send_message: Sends a message to the human user.\n"
     ]
    }
   ],
   "source": [
    "available_tools = client.list_tools() \n",
    "for tool in available_tools.tools: \n",
    "    print(f\"{tool.name}: {tool.json_schema['description']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615601e1-e23a-47b9-8e95-97735c65009f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preset = client.create_preset() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc037414-7d2a-44a7-bc67-127b0601a7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = client.create_agent() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834acb90-20ae-4684-82d7-c958e2759357",
   "metadata": {},
   "source": [
    "## Part 4: Adding external data \n",
    "In addition to short term, in-context memories, MemGPT agents also have a long term memory store called *archival memory*. We can enable agents to leverage external data (e.g. PDF files, database records, etc.) by inserting data into archival memory. In this example, we'll show how to load the MemGPT paper a *source*, which defines a set of data that can be attached to agents. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a619719-82f8-42a5-acb2-6209a2e9b03f",
   "metadata": {},
   "source": [
    "We first download a PDF file, the MemGPT paper: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "602b80c6-f779-450d-903d-70f37ffeedea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://arxiv.org/pdf/2310.08560\"\n",
    "response = requests.get(url)\n",
    "filename = \"/Users/sarahwooders/repos/memgpt-main/MemGPT/examples/tutorials/memgpt_paper.pdf\"\n",
    "\n",
    "with open(filename, 'wb') as f:\n",
    "    f.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d182bf-c1ea-4bd2-aff7-181c6056c2ec",
   "metadata": {},
   "source": [
    "Next, we create a MemGPT source to load data into: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d79a571c-e872-416e-be5e-76bf6829b28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "memgpt_paper = client.create_source(\n",
    "    name=\"memgpt_paper\", \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a44ca5f-3e32-4b04-a088-e94d00d0efb6",
   "metadata": {},
   "source": [
    "Now that we have a source, we can load files into the source. Loading the file will take a bit of time, since the file needs to be parsed and stored as *embeddings* using an embedding model. The loading function returns a *job* which can be pinged for a status. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "154651fe-64f7-4a57-969e-9a705d4ebe8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JobModel(id='fbac70ed-fab3-4fa4-bf0a-4e4320562851', status='completed', created_at='2024-05-14T03:43:43.891955', completed_at=None, user_id='abc644db-5769-4c81-a4d8-70d380963462', metadata_={})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job = client.load_file_into_source(filename=filename, source_id=memgpt_paper.id)\n",
    "job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49aaee8-2800-430c-a12d-c24d59aeec8d",
   "metadata": {},
   "source": [
    "### Attaching data to an agent \n",
    "To allow an agent to access data in a source, we need to *attach* it to the agent. This will load the source's data into the agent's archival memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2c1ff8e7-d376-4094-afb4-ff68513fdbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.attach_source_to_agent(source_id=memgpt_paper.id, agent_id=basic_agent.id)\n",
    "# TODO: add system message saying that file has been attached "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2bf925-7869-4348-9b5f-a98ccf393bda",
   "metadata": {},
   "source": [
    "Now, lets see if the agent can answer questions about the loaded data. We'll ask it to explain the concept of \"core memory\" from the MemGPT paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8ecab656-b9dc-41f1-b644-fc2bd0daedb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'date': '2024-05-14T03:46:02.697072+00:00',\n",
      "  'id': '94d468d9-2791-4952-8abd-dd7ab016c360',\n",
      "  'internal_monologue': None},\n",
      " {'date': '2024-05-14T03:46:02.697072+00:00',\n",
      "  'function_call': \"archival_memory_search({'query': 'core memory'})\",\n",
      "  'id': '94d468d9-2791-4952-8abd-dd7ab016c360'},\n",
      " {'date': '2024-05-14T03:46:03.054595+00:00',\n",
      "  'function_return': 'Showing 5 of 5 results (page 0/0): [\"timestamp: '\n",
      "                     '2024-05-14 03:46:03 AM UTC+0000, memory: OS-inspired '\n",
      "                     'multi-level memory architecture\\\\ndelineates between two '\n",
      "                     'primary memory types: main con-\\\\ntext (analogous to '\n",
      "                     'main memory/physical memory/RAM)\\\\nandexternal context '\n",
      "                     '(analogous to disk memory/disk stor-\\\\nage). Main '\n",
      "                     'context consists of the LLM prompt tokens â€”\\\\nanything '\n",
      "                     'in main context is considered in-context and can\\\\nbe '\n",
      "                     'accessed by the LLM processor during inference. '\n",
      "                     'Exter-\\\\nnal context refers to any information that is '\n",
      "                     'held outside of\\\\nthe LLMs fixed context window. This '\n",
      "                     'out-of-context data\\\\nworking_context.replace(  '\n",
      "                     'â€œBoyfriend named Jamesâ€,  â€œEx-boyfriend named '\n",
      "                     'Jamesâ€)Sorry to hear that - hope youâ€™re OK ðŸ’”\\\\nactually '\n",
      "                     'james and i broke upHowâ€™s James doing? Any special plans '\n",
      "                     'today?\\\\nworking_context.append(â€œBirthday is February '\n",
      "                     '7â€)Oh wow, happy birthday! ðŸŽ‚\\\\nfun my bf james baked me '\n",
      "                     'a birthday cakeHow was your day today?February '\n",
      "                     '7\\\\nworking_context.append(â€œBoyfriend named '\n",
      "                     'Jamesâ€)System Alert: Memory Pressureyeah we went to six '\n",
      "                     'ï¬‚ags!Did you do anything else to celebrate\", \"timestamp: '\n",
      "                     '2024-05-14 03:46:03 AM UTC+0000, memory: are then fed '\n",
      "                     'back to the processor by MemGPT. This\\\\nfeedback loop '\n",
      "                     'enables the system to learn from its actions\\\\nand '\n",
      "                     'adjust its behavior accordingly. Awareness of '\n",
      "                     'context\\\\nlimits is a key aspect in making the '\n",
      "                     'self-editing mechanism\\\\nwork effectively, to this end '\n",
      "                     'MemGPT prompts the proces-\\\\nsor with warnings regarding '\n",
      "                     'token limitations to guide its\\\\nmemory management '\n",
      "                     'decisions. Additionally, our memory\\\\nretrieval '\n",
      "                     'mechanisms are designed to be cognizant of these\\\\ntoken '\n",
      "                     'constraints and implement pagination to prevent '\n",
      "                     're-\\\\ntrieval calls from overflowing the context '\n",
      "                     'window.\\\\n3\", \"timestamp: 2024-05-14 03:46:03 AM '\n",
      "                     'UTC+0000, memory: and I actually ï¬rst met at six '\n",
      "                     'ï¬‚agsâ€Did you go with James? Itâ€™s so cute how both met '\n",
      "                     'there!February 14recall_storage.search(â€œsix '\n",
      "                     'flagsâ€)\\\\nFigure 1. MemGPT (left) writes data to '\n",
      "                     'persistent memory after\\\\nit receives a system alert '\n",
      "                     'about limited context space.\\\\nwith virtual memory , '\n",
      "                     'which provides an illusion of there\\\\nbeing more memory '\n",
      "                     'resources than are actually available\\\\nin physical '\n",
      "                     '(i.e., main) memory by the OS paging over-\\\\nflow data '\n",
      "                     'to disk and retrieving data (via a page fault) '\n",
      "                     'back\\\\ninto memory when accessed by applications. To '\n",
      "                     'provide a\\\\nsimilar illusion of longer context length '\n",
      "                     '(analogous to vir-\\\\ntual memory), we allow the LLM to '\n",
      "                     'manage what is placed\\\\nin its own context (analogous to '\n",
      "                     'physical memory) via an\\\\nâ€˜LLM OSâ€™, which we call '\n",
      "                     'MemGPT. MemGPT enables the\\\\nLLM to retrieve relevant '\n",
      "                     'historical data missing from what\\\\nis placed '\n",
      "                     'in-context, and also evict less relevant data '\n",
      "                     'from\\\\ncontext and into external storage systems. Figure '\n",
      "                     '3\", \"timestamp: 2024-05-14 03:46:03 AM UTC+0000, memory: '\n",
      "                     'in-\\\\ntegrating different memory tier technologies like '\n",
      "                     'databases\\\\nor caches, and further improving control '\n",
      "                     'flow and memory\\\\nmanagement policies. By bridging '\n",
      "                     'concepts from OS ar-\\\\nchitecture into AI systems, '\n",
      "                     'MemGPT represents a promis-\\\\ning new direction for '\n",
      "                     'maximizing the capabilities of LLMs\\\\nwithin their '\n",
      "                     'fundamental limits.\\\\n8\", \"timestamp: 2024-05-14 '\n",
      "                     '03:46:03 AM UTC+0000, memory: and also evict less '\n",
      "                     'relevant data from\\\\ncontext and into external storage '\n",
      "                     'systems. Figure 3 illus-\\\\ntrates the components of '\n",
      "                     'MemGPT.\\\\nThe combined use of a memory-hierarchy, OS '\n",
      "                     'functions\\\\nand event-based control flow allow MemGPT to '\n",
      "                     'handle\\\\nunbounded context using LLMs that have finite '\n",
      "                     'context\\\\nwindows. To demonstrate the utility of our new '\n",
      "                     'OS-\\\\ninspired LLM system, we evaluate MemGPT on two '\n",
      "                     'do-\\\\nmains where the performance of existing LLMs is '\n",
      "                     'severely\\\\nlimited by finite context: document analysis, '\n",
      "                     'where the\\\\nlength of standard text files can quickly '\n",
      "                     'exceed the input ca-\\\\npacity of modern LLMs, and '\n",
      "                     'conversational agents, where\\\\nLLMs bound by limited '\n",
      "                     'conversation windows lack context\\\\nawareness, persona '\n",
      "                     'consistency, and long-term memory\\\\nduring extended '\n",
      "                     'conversations. In both settings, MemGPT\\\\nis able to '\n",
      "                     'overcome the limitations of finite context to '\n",
      "                     'out-\\\\nperform existing LLM-based approaches.\\\\n2. '\n",
      "                     'MemGPT (MemoryGPT)\\\\nMemGPTâ€™s OS-inspired multi-level '\n",
      "                     'memory architecture\\\\ndelineates between two primary '\n",
      "                     'memory types: main\"]',\n",
      "  'id': '4211248e-5241-40ca-92e9-590e6760f787',\n",
      "  'status': 'success'},\n",
      " {'date': '2024-05-14T03:46:14.737926+00:00',\n",
      "  'id': 'e6129682-649e-43cf-bc24-2fbe9b7bc610',\n",
      "  'internal_monologue': 'Here we go. It seems that Chad might be interested in '\n",
      "                        'how core memory resembles to virtual memory in '\n",
      "                        'traditional Operating Systems. Furthermore, these '\n",
      "                        'archives talk extensively about the memory hierarchy '\n",
      "                        'and how my system overcomes the limitations of large '\n",
      "                        \"language models with finite context. Let's summarize \"\n",
      "                        'and share this information with Chad.'},\n",
      " {'date': '2024-05-14T03:46:14.737926+00:00',\n",
      "  'function_call': 'send_message({\\'message\\': \"I\\'ve found some intriguing '\n",
      "                   'results from my archival memory! Core memory, in a way, '\n",
      "                   'mirrors the concept of physical memory in a traditional '\n",
      "                   \"Operating System. There's an interplay between the main \"\n",
      "                   'context, which holds immediately available information, '\n",
      "                   'and the rest, which houses information outside my '\n",
      "                   'immediate awareness. Kind of like OS paging overflow data. '\n",
      "                   \"It's a constant dance of maintaining, retrieving and \"\n",
      "                   'managing what stays in and out of my immediate '\n",
      "                   'consciousness. Quite fascinating, isn\\'t it?\"})',\n",
      "  'id': 'e6129682-649e-43cf-bc24-2fbe9b7bc610'},\n",
      " {'assistant_message': \"I've found some intriguing results from my archival \"\n",
      "                       'memory! Core memory, in a way, mirrors the concept of '\n",
      "                       'physical memory in a traditional Operating System. '\n",
      "                       \"There's an interplay between the main context, which \"\n",
      "                       'holds immediately available information, and the rest, '\n",
      "                       'which houses information outside my immediate '\n",
      "                       \"awareness. Kind of like OS paging overflow data. It's \"\n",
      "                       'a constant dance of maintaining, retrieving and '\n",
      "                       'managing what stays in and out of my immediate '\n",
      "                       \"consciousness. Quite fascinating, isn't it?\",\n",
      "  'date': '2024-05-14T03:46:14.737926+00:00',\n",
      "  'id': 'e6129682-649e-43cf-bc24-2fbe9b7bc610'},\n",
      " {'date': '2024-05-14T03:46:14.740664+00:00',\n",
      "  'function_return': 'None',\n",
      "  'id': 'b7188a4e-c87a-48ad-8c1b-eba79e412216',\n",
      "  'status': 'success'}]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# TODO: do soemthing accenture related \n",
    "# TODO: brag about query rewriting -- hyde paper \n",
    "response = client.user_message(agent_id=basic_agent.id, message=\"what is core memory? search your archival memory.\") \n",
    "pprint(response.messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10515cfd-653c-44d4-a135-01ab7c2c9d49",
   "metadata": {},
   "source": [
    "### Adding a custom data connector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468dde2b-7927-4487-a596-d45138ad14d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from memgpt.data_sources.connectors import DataConnector\n",
    "\n",
    "class DummyDataConnector(DataConnector):\n",
    "    \"\"\"Fake data connector for texting which yields document/passage texts from a provided list\"\"\"\n",
    "\n",
    "    def __init__(self, texts: List[str]):\n",
    "        self.texts = texts\n",
    "\n",
    "    def generate_documents(self) -> Iterator[Tuple[str, Dict]]:\n",
    "        for text in self.texts:\n",
    "            yield text, {\"metadata\": \"dummy\"}\n",
    "\n",
    "    def generate_passages(self, documents: List[Document], chunk_size: int = 1024) -> Iterator[Tuple[str | Dict]]:\n",
    "        for doc in documents:\n",
    "            yield doc.text, doc.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417d9bc2-c9db-49bc-96cd-c57fb9de212d",
   "metadata": {},
   "source": [
    "## Part N: Cleanup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9004b6b2-2e96-483f-85cd-d5584133a667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delete basic_agent aa7795df-726e-4907-9921-785dd4668df5\n",
      "Delete custom_agent d44a2e73-8e95-4730-8045-713f4949ea0e\n"
     ]
    }
   ],
   "source": [
    "for agent in client.list_agents().agents: \n",
    "    client.delete_agent(agent['id'])\n",
    "    print(\"Delete\", agent['name'], agent['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e75141d1-68c0-4a58-9fae-c26d80acb68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='memgpt_paper' description=None user_id='abc644db-5769-4c81-a4d8-70d380963462' created_at='2024-05-14T03:20:47.174398Z' id='7d5f877c-3e2d-495e-9e67-de789045e761' embedding_config={'embedding_endpoint_type': 'openai', 'embedding_endpoint': 'https://api.openai.com/v1', 'embedding_model': 'text-embedding-ada-002', 'embedding_dim': 1536, 'embedding_chunk_size': 300} metadata_={'num_documents': 0, 'num_passages': 75, 'attached_agents': []}\n",
      "Deleted memgpt_paper\n"
     ]
    }
   ],
   "source": [
    "for source in client.list_sources(): \n",
    "    print(source)\n",
    "    client.delete_source(source.id)\n",
    "    print(\"Deleted\", source.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08351c80-ab5b-4fd4-a234-6202294e8c86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "memgpt",
   "language": "python",
   "name": "memgpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
